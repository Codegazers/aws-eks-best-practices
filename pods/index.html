<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>Pod Security - EKS Security Best Practices</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.1, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href=".." target="_blank" class="custom-link">EKS Security Best Practices</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="..">Home</a>
<li class="chapter" data-path="iam/">
<a href="../iam/">Identity and Access Management</a>
<li class="chapter active" data-path="pods/">
<a href="./">Pod Security</a>
<li class="chapter" data-path="multitenancy/">
<a href="../multitenancy/">Multi-tenancy</a>
<li class="chapter" data-path="detective/">
<a href="../detective/">Detective Controls</a>
<li class="chapter" data-path="network/">
<a href="../network/">Network Security</a>
<li class="chapter" data-path="data/">
<a href="../data/">Data Encryption and Secrets Management</a>
<li class="chapter" data-path="runtime/">
<a href="../runtime/">Runtime Security</a>
<li class="chapter" data-path="hosts/">
<a href="../hosts/">Infrastructure Security</a>
<li class="chapter" data-path="compliance/">
<a href="../compliance/">Regulatory Compliance</a>
<li class="chapter" data-path="incidents/">
<a href="../incidents/">Incident Response and Forensics</a>
<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="pod-security">Pod Security<a class="headerlink" href="#pod-security" title="Permanent link">&para;</a></h1>
<p>Pods have variety of different settings that can strengthen or weaken your overall security posture.  As a Kubernetes practitioner your chief concern should be preventing a process that’s running in a container from escaping the isolation boundaries of Docker and gaining access to the underlying host.  The reason for this is twofold.  First, the processes that run within a container run under the context of the [Linux] root user by default.  Although the actions of root within a container are partially constrained by the set of Linux capabilities that Docker assigns to the containers, these default privileges could allow an attacker to escalate their privileges and/or gain access to sensitive information bound to the host, including Secrets and ConfigMaps.  Below is a list of the default capabilities assigned to Docker containers.  For additional information about each capability, see http://man7.org/linux/man-pages/man7/capabilities.7.html.</p>
<p><code>CAP_CHOWN, CAP_DAC_OVERERIDE, CAP_FOWNER, CAP_FSETID, CAP_KILL, CAP_SETGID, CAP_SETUID, CAP_SETPCAP, CAP_NET_BIND_SERVICE, CAP_NET_RAW, CAP_SYS_CHROOT, CAP_MKNOD, CAP_AUDIT_WRITE, CAP_SETFCAP</code></p>
<p>Pods that are run as privileged, inherit <em>all</em> of the Linux capabilities associated with root on the host and should be avoided if possible.</p>
<p>Second, all Kubernetes worker nodes use an authorization mode called the node authorizer.  The node authorizer authorizes all API requests that originate from the kubelet and allows nodes to perform the following actions: </p>
<p>Read operations:</p>
<ul>
<li>services</li>
<li>endpoints</li>
<li>nodes</li>
<li>pods</li>
<li>secrets, configmaps, persistent volume claims and persistent volumes related to pods bound to the kubelet’s node</li>
</ul>
<p>Write operations:</p>
<ul>
<li>nodes and node status (enable the <code>NodeRestriction</code> admission plugin to limit a kubelet to modify its own node)</li>
<li>pods and pod status (enable the <code>NodeRestriction</code> admission plugin to limit a kubelet to modify pods bound to itself)</li>
<li>events</li>
</ul>
<p>Auth-related operations:</p>
<ul>
<li>read/write access to the certificationsigningrequests API for TLS bootstrapping</li>
<li>the ability to create tokenreviews and subjectaccessreviews for delegated authentication/authorization checks</li>
</ul>
<p>EKS uses the <a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#noderestriction">node restriction admission controller</a> which only allows the node to modify a limited set of node attributes and pod objects that are bound to the node.   Nevertheless, an attacker who manages to get access to the host will still be able to glean sensitive information about the environment from the Kubernetes API that could allow them to move laterally within the cluster.</p>
<h2 id="recommendations">Recommendations<a class="headerlink" href="#recommendations" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p><strong>Restrict the containers that can run as privileged</strong>.  As mentioned, containers that run as privileged inherit all of the Linux capabilities assigned to root on the host.  Seldom do containers need these types of privileges to function properly.  You can reject pods with containers configured to run as privileged by creating a <a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/">pod security policy</a>.  You can think of a pod security policy as a set requirements that pods have to meet before they can be created.  If you elect to use pod security policies, you will need to create a role binding that allows service accounts to read your pod security policies. </p>
<p>When you provision an EKS cluster, a pod security policy called <code>eks.privileged</code> is automatically created.  The manifest for that policy appears below: </p>
</li>
</ul>
<pre><code class="yaml">apiVersion: extensions/v1beta1
kind: PodSecurityPolicy
metadata:
  annotations:
    kubernetes.io/description: privileged allows full unrestricted access to pod features,
      as if the PodSecurityPolicy controller was not enabled.
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
  labels:
    eks.amazonaws.com/component: pod-security-policy
    kubernetes.io/cluster-service: &quot;true&quot;
  name: eks.privileged
spec:
  allowPrivilegeEscalation: true
  allowedCapabilities:
  - '*'
  fsGroup:
    rule: RunAsAny
  hostIPC: true
  hostNetwork: true
  hostPID: true
  hostPorts:
  - max: 65535
    min: 0
  privileged: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
  - '*'
</code></pre>

<p>This PSP allows an authenticated user to run privileged containers across all namespaces within the cluster.  While this may seem overly permissive at first, there are certain applications/plug-ins such as the AWS VPC CNI and kube-proxy that have to run as privileged because they are responsible for configuring the host’s network settings. Furthermore, this policy provides backward compatibility with earlier versions of Kubernetes that lacked support for pod security policies.    </p>
<p>The binding shown below is what binds the ClusterRole <code>eks:podsecuritypolicy:privileged</code> to the <code>system:authenticated</code> RBAC group. </p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations: 
    kubernetes.io/description: Allow all authenticated users to create privileged
  labels:
    eks.amazonaws.com/component: pod-security-policy
    kubernetes.io/cluster-service: &quot;true&quot;
  name: eks:podsecuritypolicy:authenticated
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: eks:podsecuritypolicy:privileged
subjects:
- apiGroup: rbac.authorization.k8s.io
  kind: Group
  name: system:authenticated
</code></pre>

<p>Lastly, the ClusterRole below allow all bindings that reference it to use the <code>eks.privileged</code> PodSecurityPolicy.</p>
<pre><code class="yaml">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    eks.amazonaws.com/component: pod-security-policy
    kubernetes.io/cluster-service: &quot;true&quot;
  name: eks:podsecuritypolicy:privileged
rules:
- apiGroups:
  - policy
  resourceNames:
  - eks.privileged
  resources:
  - podsecuritypolicies
  verbs:
  - use
</code></pre>

<p>As a best practice we recommend that you scope the binding for privileged pods to service accounts within a particular namespace, e.g. kube-system, and limiting access to that namespace.  For all other serviceaccounts/namespaces, we recommend implementing a more restrictive policy such as this: </p>
<pre><code class="yaml">apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
    name: restricted
    annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default,runtime/default'
    apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'
    seccomp.security.alpha.kubernetes.io/defaultProfileName:  'runtime/default'
    apparmor.security.beta.kubernetes.io/defaultProfileName:  'runtime/default'
spec:
    privileged: false
    # Required to prevent escalations to root.
    allowPrivilegeEscalation: false
    # This is redundant with non-root + disallow privilege escalation,
    # but we can provide it for defense in depth.
    requiredDropCapabilities:
    - ALL
    # Allow core volume types.
    volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    # Assume that persistentVolumes set up by the cluster admin are safe to use.
    - 'persistentVolumeClaim'
    hostNetwork: false
    hostIPC: false
    hostPID: false
    runAsUser:
    # Require the container to run without root privileges.
    rule: 'MustRunAsNonRoot'
    seLinux:
    # This policy assumes the nodes are using AppArmor rather than SELinux.
    rule: 'RunAsAny'
    supplementalGroups:
    rule: 'MustRunAs'
    ranges:
        # Forbid adding the root group.
        - min: 1
        max: 65535
    fsGroup:
    rule: 'MustRunAs'
    ranges:
        # Forbid adding the root group.
        - min: 1
        max: 65535
    readOnlyRootFilesystem: false
</code></pre>

<p>This policy prevents pods from running as privileged or escalating privileges.  It also restricts the types of volumes that can be mounted and the root supplemental groups that can be added. </p>
<blockquote>
<p><strong>Fargate</strong> is a launch type that enables you to run "serverless" container(s) where the containers of a pod are run on infrastructure that AWS manages. With Fargate, you cannot run a privileged container or  configure your pod to use hostNetwork or hostPort.</p>
</blockquote>
<ul>
<li>
<p><strong>Do not run processes in containers as root</strong>. All containers run as root by default.  This could be problematic if an attacker is able to exploit a vulnerability in the application and get shell access to the running container.  You can mitigate this risk a variety of ways.  First, by removing the shell from the container image.  Second, adding the USER directive to your Dockerfile or running the containers in the pod as a non-root user.  The Kubernetes podSpec includes a set of fields under <code>spec.securityContext</code>, that allow to let you specify the user and/or group to run your application as.  These fields are <code>runAsUser</code> and <code>runAsGroup</code> respectively.  You can mandate the use of these fields by creating a pod security policy.  See https://kubernetes.io/docs/concepts/policy/pod-security-policy/#users-and-groups for further information on this topic. </p>
</li>
<li>
<p><strong>Restrict the use of hostPath or if hostPath is necessary restrict which prefixes can be used and configure the volume as read-only</strong>. <code>hostPath</code> is a volume that mounts a directory from the host directly to the container.  Rarely will pods need this type of access, but if they do, you need to be aware of the risks.  By default pods that run as root will have write access to the file system exposed by hostPath.  This could allow an attacker to modify the kubelet settings, create symbolic links to directories or files not directly exposed by the hostPath, e.g. /etc/shadow, install ssh keys, read secrets mounted to the host, and other malicious things. To mitigate the risks from hostPath, configure the <code>spec.containers.volumeMounts</code> as <code>readOnly</code>, for example: </p>
</li>
</ul>
<pre><code class="yaml">volumeMounts:
- name: hostPath-volume
    readOnly: true
    mountPath: /host-path
</code></pre>

<p>You should also use a pod security policy to restrict the directories that can be used by <code>hostPath</code> volumes.  For example the following PSP excerpt only allows paths that begin with <code>/foo</code>.  It will prevent containers from traversing the host file system from outside the prefix: </p>
<pre><code class="yaml">allowedHostPaths:
# This allows &quot;/foo&quot;, &quot;/foo/&quot;, &quot;/foo/bar&quot; etc., but
# disallows &quot;/fool&quot;, &quot;/etc/foo&quot; etc.
# &quot;/foo/../&quot; is never valid.
- pathPrefix: &quot;/foo&quot;
    readOnly: true # only allow read-only mounts
</code></pre>

<ul>
<li>
<p><strong>Set requests and limits for each container to avoid resource contention and DoS attacks</strong>. A pod without requests or limits can theoretically consume all of the resources available on a host.  As additional pods are scheduled onto a node, the node may experience CPU or memory pressure which can cause the Kubelet to terminate or evict pods from the node.  While you can’t prevent this from happening all together, setting requests and limits will help minimize resource contention and mitigate the risk from poorly written applications that consume an excessive amount of resources. </p>
<p>The <code>podSpec</code> allows you to specify requests and limits for CPU and memory.  CPU is considered a compressible resource because it can be oversubscribed.  Memory is incompressible, i.e. it cannot be shared among multiple containers.  </p>
<p>When you specify <em>requests</em> for CPU or memory, you’re essentially designating the amount of <em>memory</em> that containers are guaranteed to get.  Kubernetes aggregates the requests of all the containers in a pod to determine which node to schedule the pod onto.  If a container exceeds the requested amount of memory it may be subject to termination if there’s memory pressure on the node. </p>
<p><em>Limits</em> are the maximum amount of CPU and memory resources that a container is allowed to consume and directly corresponds to the <code>memory.limit_in_bytes</code> value of the cgroup created for the container.  A container that exceeds the memory limit will be OOM killed. If a container exceeds its CPU limit, it will be throttled. </p>
<p>Kubernetes uses 3 Quality of Service (QoS) classes to prioritize the workloads running on a node.  These include: guaranteed, burstable, and best effort.  If limits and requests are not set, the pod is configured as burstable (lowest priority).  Burstable pods are the first to get killed when there is insufficient memory.  If limits are set on <em>all</em> containers within the pod, or if the requests and limits are set to the same values, the pod is configured as guaranteed (higheest priority).  Guaranteed pods will not be killed unless they exceed their configured memory limits. If the limits and requests are configured with different values, or 1 container within the pod sets limits and the other don’t or have limits set for different resources, the pods are configured as burstable (medium priority). These pods have some resource guarantees, but can be killed once they exceed their requested memory. Be aware that requests doesn’t actually affect the <code>memory_limit_in_bytes</code> value of the cgroup; the cgroup limit is set to the amount of memory available on the host. Nevertheless, setting the requests value too low could cause the pod to be targeted for termination by the kubelet if the node undergoes memory pressure. </p>
<p>For additional information about resource QoS, see https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md</p>
<p>You can force the use of requests and limits by setting a <a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/">resource quota</a> on a namespace or by creating a <a href="https://kubernetes.io/docs/concepts/policy/limit-range/">limit range</a>.  A resource quota allows you to specify the total amount of resources, e.g. CPU and RAM, allocated to a namespace.  When it’s applied to a namespace, it forces you to specify requests and limits for all containers deployed into that namespace. By contrast, limit ranges give you more granular control of the allocation of resources. With limit ranges you can min/max for CPU and memory resources per pod or per container within a namespace.  You can also use them to set default request/limit values if none are provided.  </p>
</li>
<li>
<p><strong>Do not allow privileged escalation</strong>. Privileged escalation allows a process to change the security context under which its running.  Sudo is a good example of this as are binaries with the SUID or SGID bit.  Privileged escalation is basically a way for users to execute a file with the permissions of another user or group.  You can prevent a container from privileged escalation by implementing a pod security policy that sets <code>allowPriviledgedEscalation</code> to <code>false</code> or by setting <code>securityContext.allowPrivilegedEscalation</code> in the <code>podSpec</code>.  </p>
</li>
</ul>
<h3 id="additional-resources">Additional Resources<a class="headerlink" href="#additional-resources" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://github.com/sysdiglabs/kube-psp-advisor">kube-psp-advisor</a> is a tool that makes it easier to create K8s Pod Security Policies (PSPs) from either a live K8s environment or from a single .yaml file containing a pod specification (Deployment, DaemonSet, Pod, etc).</li>
</ul>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../js/main.js"></script>
<script src="../search/main.js"></script>
<script src="../js/gitbook.min.js"></script>
<script src="../js/theme.min.js"></script>
</body>
</html>